{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","authorship_tag":"ABX9TyMLCn/l4a/cDsRd2NjifU26"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ChafaYoWPIPF","executionInfo":{"status":"ok","timestamp":1719459380371,"user_tz":240,"elapsed":142444,"user":{"displayName":"Shaurya Mantrala","userId":"12085222137758312823"}},"outputId":"ebd0cacc-272c-4457-f0b5-1532782650c1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n","219055592/219055592 [==============================] - 8s 0us/step\n","Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n","                                                                 \n"," inception_resnet_v2 (Funct  (None, 5, 5, 1536)        54336736  \n"," ional)                                                          \n","                                                                 \n"," global_average_pooling2d (  (None, 1536)              0         \n"," GlobalAveragePooling2D)                                         \n","                                                                 \n"," dense (Dense)               (None, 1024)              1573888   \n","                                                                 \n"," dropout (Dropout)           (None, 1024)              0         \n","                                                                 \n"," dense_1 (Dense)             (None, 2)                 2050      \n","                                                                 \n","=================================================================\n","Total params: 55912674 (213.29 MB)\n","Trainable params: 1575938 (6.01 MB)\n","Non-trainable params: 54336736 (207.28 MB)\n","_________________________________________________________________\n","Epoch 1/13\n","18/18 [==============================] - 30s 744ms/step - loss: 0.9246 - accuracy: 0.5278 - val_loss: 0.6907 - val_accuracy: 0.5455\n","Epoch 2/13\n","18/18 [==============================] - 7s 395ms/step - loss: 0.8269 - accuracy: 0.5727 - val_loss: 0.6894 - val_accuracy: 0.5455\n","Epoch 3/13\n","18/18 [==============================] - 6s 348ms/step - loss: 0.7103 - accuracy: 0.5889 - val_loss: 0.6895 - val_accuracy: 0.5455\n","Epoch 4/13\n","18/18 [==============================] - 7s 363ms/step - loss: 0.6691 - accuracy: 0.6140 - val_loss: 0.6897 - val_accuracy: 0.5455\n","Epoch 5/13\n","18/18 [==============================] - 7s 367ms/step - loss: 0.6830 - accuracy: 0.5907 - val_loss: 0.6892 - val_accuracy: 0.5455\n","Epoch 6/13\n","18/18 [==============================] - 6s 347ms/step - loss: 0.6316 - accuracy: 0.6481 - val_loss: 0.6892 - val_accuracy: 0.5455\n","Epoch 7/13\n","18/18 [==============================] - 6s 343ms/step - loss: 0.6347 - accuracy: 0.6320 - val_loss: 0.6892 - val_accuracy: 0.5455\n","Epoch 8/13\n","18/18 [==============================] - 7s 365ms/step - loss: 0.6062 - accuracy: 0.6732 - val_loss: 0.6892 - val_accuracy: 0.5455\n","6/6 [==============================] - 2s 413ms/step - loss: 0.6758 - accuracy: 0.6000\n","Test accuracy: 0.6000000238418579\n"]}],"source":["import tensorflow as tf\n","from tensorflow.keras import layers, Model\n","from tensorflow.keras.applications import InceptionResNetV2\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n","from sklearn.utils import shuffle\n","import numpy as np\n","import pandas as pd\n","import os\n","import cv2\n","\n","# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Define path to dataset\n","path = '/content/drive/MyDrive/NeurIPS/all_eye_images'\n","dataset_path = os.listdir(path)\n","im_size = 224\n","images = []\n","labels = []\n","\n","# Load and preprocess images\n","for i in dataset_path:\n","    data_path = path + '/' + str(i)\n","    filenames = [i for i in os.listdir(data_path)]\n","    for f in filenames:\n","        img = cv2.imread(data_path + '/' + f)\n","        img = cv2.resize(img, (im_size, im_size))\n","        images.append(img)\n","        labels.append(i)\n","\n","images = np.array(images)\n","images = images.astype('float32')\n","images /= 255.0\n","\n","# Encode labels\n","label_encoder = LabelEncoder()\n","labels = label_encoder.fit_transform(labels)\n","labels = labels.reshape(-1, 1)\n","\n","# One-hot encode labels\n","onehot_encoder = OneHotEncoder(sparse=False)\n","labels = onehot_encoder.fit_transform(labels)\n","\n","# Shuffle and split data\n","images, labels = shuffle(images, labels, random_state=1)\n","train_x, test_x, train_y, test_y = train_test_split(images, labels, test_size=0.2, random_state=415)\n","train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size=0.15, random_state=415)\n","\n","# Data augmentation\n","train_generator = ImageDataGenerator(rotation_range=40, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n","val_generator = ImageDataGenerator(rescale = 1.0/255.)\n","test_generator = ImageDataGenerator()\n","\n","# Define Inception-ResNet model\n","base_model = InceptionResNetV2(input_shape=(im_size, im_size, 3), include_top=False, weights='imagenet')\n","base_model.trainable = False  # Freeze the base model\n","\n","inputs = layers.Input(shape=(im_size, im_size, 3))\n","x = base_model(inputs, training=False)\n","x = layers.GlobalAveragePooling2D()(x)\n","x = layers.Dense(1024, activation='relu')(x)\n","x = layers.Dropout(0.5)(x)\n","\n","outputs = layers.Dense(2, activation='softmax')(x)\n","\n","model = Model(inputs, outputs)\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Callbacks\n","early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n","\n","# Model summary\n","model.summary()\n","\n","# Train model\n","history = model.fit(train_generator.flow(train_x, train_y, batch_size=32), epochs=13, callbacks=[early_stopping], validation_data=val_generator.flow(val_x, val_y, batch_size=32))\n","\n","# Evaluate model\n","test_loss, test_accuracy = model.evaluate(test_x, test_y)\n","print(f'Test accuracy: {test_accuracy}')\n"]}]}