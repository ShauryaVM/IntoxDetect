{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HF7VSYpoNvO",
        "outputId": "3ac8fb12-64f7-4227-fdfb-809bb4925760"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r          1SLclsq_k     [<=>                 ]       0  --.-KB/s               \r1SLclsq_kKL27VgVjq2     [ <=>                ] 167.67K  --.-KB/s    in 0.02s   \n"
          ]
        }
      ],
      "source": [
        "!wget -q --show-progress https://drive.google.com/drive/folders/1SLclsq_kKL27VgVjq2hr8JsT45kx1pEy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sW7dcu6pq8g",
        "outputId": "2c72ff40-a1bd-4198-df26-4a43361003d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFcFfuzP5meZ"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.flush_and_unmount()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xMx3NxUk5zcx"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "def extract_frames(video_path, output_folder, frame_rate=30):\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    count = 0\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        if count % frame_rate == 0:\n",
        "            frame_name = os.path.join(output_folder, f'frame_{count}.jpg')\n",
        "            cv2.imwrite(frame_name, frame)\n",
        "        count += 1\n",
        "    cap.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1yBHaaY-55gi"
      },
      "outputs": [],
      "source": [
        "def detect_faces_and_eyes(image_path, face_cascade, eye_cascade):\n",
        "    img = cv2.imread(image_path)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
        "    eyes = []\n",
        "    for (x, y, w, h) in faces:\n",
        "        face_roi = img[y:y+h, x:x+w]\n",
        "        gray_face = gray[y:y+h, x:x+w]\n",
        "        detected_eyes = eye_cascade.detectMultiScale(gray_face)\n",
        "        for (ex, ey, ew, eh) in detected_eyes:\n",
        "            eye_roi = face_roi[ey:ey+eh, ex:ex+ew]\n",
        "            eyes.append((eye_roi, (x+ex, y+ey, ew, eh)))  # Return eye image and bounding box\n",
        "    return eyes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OhQWIoc95_GZ"
      },
      "outputs": [],
      "source": [
        "def align_and_normalize_eyes(eyes, output_size=(224, 224)):\n",
        "    normalized_eyes = []\n",
        "    for eye in eyes:\n",
        "        normalized_eye = cv2.resize(eye, output_size)\n",
        "        normalized_eyes.append(normalized_eye)\n",
        "    return normalized_eyes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayeYcgDJ6CSo"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "\n",
        "def augment_eyes(eye_images):\n",
        "    datagen = ImageDataGenerator(\n",
        "        rotation_range=20,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        brightness_range=[0.8, 1.2],\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True\n",
        "    )\n",
        "    augmented_images = []\n",
        "    for eye_image in eye_images:\n",
        "        eye_image = eye_image.reshape((1, ) + eye_image.shape)  # Reshape for Keras\n",
        "        for batch in datagen.flow(eye_image, batch_size=1):\n",
        "            augmented_images.append(batch[0])\n",
        "            if len(augmented_images) >= 5:  # Limiting to 5 augmentations per image for example\n",
        "                break\n",
        "    return np.array(augmented_images)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "MnaxJX3e6Kkk",
        "outputId": "9e1f04ba-37cb-4202-fffb-073460eb563e"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'face_cascade' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-de6249cfaec6>\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m                     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meye_image_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meye_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mprocess_videos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-20-de6249cfaec6>\u001b[0m in \u001b[0;36mprocess_videos\u001b[0;34m(dataset_folder)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mframe_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'*.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mframe_file\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mframe_files\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0meyes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect_faces_and_eyes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mface_cascade\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meye_cascade\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0meyes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0maligned_eyes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malign_and_normalize_eyes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meyes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'face_cascade' is not defined"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "\n",
        "dataset_folder = '/content/drive/MyDrive/NeurIPS/Code/Dataset(LPW)/LPW/1'\n",
        "\n",
        "def process_videos(dataset_folder):\n",
        "    video_files = glob.glob(os.path.join(dataset_folder, '*.avi'))\n",
        "    for video_file in video_files:\n",
        "        video_name = os.path.basename(video_file).split('.')[0]\n",
        "        frames_folder = os.path.join(dataset_folder, video_name, 'frames')\n",
        "        extract_frames(video_file, frames_folder)\n",
        "\n",
        "        frame_files = glob.glob(os.path.join(frames_folder, '*.jpg'))\n",
        "        for frame_file in frame_files:\n",
        "\n",
        "            eyes = detect_faces_and_eyes(frame_file, face_cascade, eye_cascade)\n",
        "            if eyes:\n",
        "                aligned_eyes = align_and_normalize_eyes(eyes)\n",
        "                augmented_eyes = augment_eyes(aligned_eyes)\n",
        "                # Save or use the augmented eye images\n",
        "                for idx, eye_image in enumerate(augmented_eyes):\n",
        "                    eye_image_path = os.path.join(dataset_folder, video_name, 'eyes', f'eye_{idx}.jpg')\n",
        "                    if not os.path.exists(os.path.dirname(eye_image_path)):\n",
        "                        os.makedirs(os.path.dirname(eye_image_path))\n",
        "                    cv2.imwrite(eye_image_path, eye_image)\n",
        "\n",
        "process_videos(dataset_folder)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OgXkpqHy8wss"
      },
      "outputs": [],
      "source": [
        "process_videos(dataset_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_tCTkOIXGdW",
        "outputId": "5116cada-e9a3-4a84-f63b-a0e839ff98ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Collecting pytube\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-15.0.0\n",
            "Collecting yt-dlp\n",
            "  Downloading yt_dlp-2024.5.27-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting brotli (from yt-dlp)\n",
            "  Downloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (2024.6.2)\n",
            "Collecting mutagen (from yt-dlp)\n",
            "  Downloading mutagen-1.47.0-py3-none-any.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycryptodomex (from yt-dlp)\n",
            "  Downloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (2.31.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.17 in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (2.0.7)\n",
            "Collecting websockets>=12.0 (from yt-dlp)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.31.0->yt-dlp) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.31.0->yt-dlp) (3.7)\n",
            "Installing collected packages: brotli, websockets, pycryptodomex, mutagen, yt-dlp\n",
            "Successfully installed brotli-1.1.0 mutagen-1.47.0 pycryptodomex-3.20.0 websockets-12.0 yt-dlp-2024.5.27\n"
          ]
        }
      ],
      "source": [
        "!pip install keras\n",
        "!pip install pytube\n",
        "!pip install yt-dlp\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0ErGZpsXW1J",
        "outputId": "1ce7ef4e-9af3-45a8-ade9-7ed4f2e35c8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import pandas as pd\n",
        "from pytube import YouTube\n",
        "import yt_dlp\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pMXcSuv4XhV9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ad59970-66c7-4d09-8132-44bb8e755ebd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                link                    name  \\\n",
            "0  https://www.youtube.com/watch?v=x24jb5ww4lQ&li...  videoplayback (40).mp4   \n",
            "1        https://www.youtube.com/watch?v=bvfEYtzq3fE  videoplayback (39).mp4   \n",
            "2        https://www.youtube.com/watch?v=4QdSIQonzI4  videoplayback (38).mp4   \n",
            "3        https://www.youtube.com/watch?v=H1KluhZpT1Y  videoplayback (37).mp4   \n",
            "4        https://www.youtube.com/watch?v=SIH90qFVT04  videoplayback (36).mp4   \n",
            "\n",
            "  Unnamed: 2  \n",
            "0        NaN  \n",
            "1        NaN  \n",
            "2        NaN  \n",
            "3        NaN  \n",
            "4        NaN  \n"
          ]
        }
      ],
      "source": [
        "# Read CSV file, trying different encodings\n",
        "csv_file_path = '/content/drive/MyDrive/NeurIPS/Code/dataset_links_drunk.csv'\n",
        "\n",
        "try:\n",
        "    df = pd.read_csv(csv_file_path, encoding='utf-8')  # Try UTF-8 first\n",
        "except UnicodeDecodeError:\n",
        "    try:\n",
        "        df = pd.read_csv(csv_file_path, encoding='latin-1')  # Try Latin-1 if UTF-8 fails\n",
        "    except UnicodeDecodeError:\n",
        "        df = pd.read_csv(csv_file_path, encoding='cp1252')  # Try cp1252 as a last resort\n",
        "\n",
        "# Extract video links\n",
        "print(df.head())\n",
        "video_links = df['link'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3aSNPPBZtHU",
        "outputId": "b01148d0-ddca-4416-c9bc-7ca41c36fde9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to download https://www.youtube.com/watch?v=yOyHVKgVH8A: yOyHVKgVH8A is unavailable\n",
            "Failed to download https://www.youtube.com/watch?v=tVMk7atYjBc: tVMk7atYjBc is a private video\n",
            "Failed to download https://www.youtube.com/watch?v=91UCO3ii8g8: 91UCO3ii8g8 is a private video\n",
            "Failed to download https://www.youtube.com/watch?v=RZ5dj-Ozwm0: RZ5dj-Ozwm0 is age restricted, and can't be accessed without logging in.\n",
            "Failed to download https://www.youtube.com/watch?v=0NbBjNiw4tk: 0NbBjNiw4tk is age restricted, and can't be accessed without logging in.\n",
            "Failed to download https://www.youtube.com/watch?v=9XjS4I4oQDY: 9XjS4I4oQDY is age restricted, and can't be accessed without logging in.\n",
            "Failed to download https://www.youtube.com/watch?v=z4QMvfMXY2c: z4QMvfMXY2c is unavailable\n",
            "Failed to download nan: expected string or bytes-like object\n",
            "Failed to download nan: expected string or bytes-like object\n",
            "Failed to download https://www.youtube.com/watch?v=d1xb0_tT5SQ: d1xb0_tT5SQ is unavailable\n",
            "Failed to download nan: expected string or bytes-like object\n",
            "Failed to download nan: expected string or bytes-like object\n",
            "Failed to download https://www.youtube.com/watch?v=KJ_e-3YJQCo: KJ_e-3YJQCo is age restricted, and can't be accessed without logging in.\n",
            "Failed to download https://www.youtube.com/watch?v=DGPbHUZQ-VE: DGPbHUZQ-VE is age restricted, and can't be accessed without logging in.\n"
          ]
        }
      ],
      "source": [
        "def download_youtube_video(url, output_path):\n",
        "    yt = YouTube(url)\n",
        "    stream = yt.streams.filter(progressive=True, file_extension='mp4').first()\n",
        "    stream.download(output_path=output_path)\n",
        "\n",
        "# Create a folder for the videos\n",
        "videos_folder = '/content/videos'\n",
        "if not os.path.exists(videos_folder):\n",
        "    os.makedirs(videos_folder)\n",
        "\n",
        "# Download each video\n",
        "for link in video_links:\n",
        "    try:\n",
        "        download_youtube_video(link, videos_folder)\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to download {link}: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P4o1ClQdCQKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VwHXV8lUeiZZ"
      },
      "outputs": [],
      "source": [
        "def extract_frames(video_path, output_folder, frame_rate=30):\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    count = 0\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        if count % frame_rate == 0:\n",
        "            frame_name = os.path.join(output_folder, f'frame_{count}.jpg')\n",
        "            cv2.imwrite(frame_name, frame)\n",
        "        count += 1\n",
        "    cap.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxMkcln-fjLI"
      },
      "outputs": [],
      "source": [
        "def detect_faces_and_eyes(image_path, face_cascade, eye_cascade):\n",
        "    img = cv2.imread(image_path)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
        "    eyes = []\n",
        "    for (x, y, w, h) in faces:\n",
        "        face_roi = img[y:y+h, x:x+w]\n",
        "        gray_face = gray[y:y+h, x:x+w]\n",
        "        detected_eyes = eye_cascade.detectMultiScale(gray_face)\n",
        "        for (ex, ey, ew, eh) in detected_eyes:\n",
        "            eye_roi = face_roi[ey:ey+eh, ex:ex+ew]\n",
        "            eyes.append((eye_roi, (x+ex, y+ey, ew, eh)))  # Return eye image and bounding box\n",
        "    return eyes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o2XBtOCjfoou"
      },
      "outputs": [],
      "source": [
        "def detect_iris_and_pupil(eye):\n",
        "    gray_eye = cv2.cvtColor(eye, cv2.COLOR_BGR2GRAY)\n",
        "    gray_eye = cv2.medianBlur(gray_eye, 5)\n",
        "    circles = cv2.HoughCircles(gray_eye, cv2.HOUGH_GRADIENT, dp=1, minDist=gray_eye.shape[0]/8,\n",
        "                               param1=100, param2=30, minRadius=10, maxRadius=30)\n",
        "    if circles is not None:\n",
        "        circles = np.uint16(np.around(circles))\n",
        "        for i in circles[0, :]:\n",
        "            center = (i[0], i[1])  # center\n",
        "            radius = i[2]  # radius\n",
        "            cv2.circle(eye, center, radius, (0, 255, 0), 2)  # Draw the outer circle\n",
        "            cv2.circle(eye, center, 2, (0, 0, 255), 3)  # Draw the center of the circle (pupil)\n",
        "    return eye"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OLDoZcgcfrxd"
      },
      "outputs": [],
      "source": [
        "def align_and_normalize_eyes(eyes, output_size=(224, 224)):\n",
        "    normalized_eyes = []\n",
        "    for eye, _ in eyes:\n",
        "        normalized_eye = cv2.resize(eye, output_size)\n",
        "        normalized_eyes.append(normalized_eye)\n",
        "    return normalized_eyes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQJk5TCTfxS2"
      },
      "outputs": [],
      "source": [
        "def augment_eyes(eye_images):\n",
        "    datagen = ImageDataGenerator(\n",
        "        rotation_range=20,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        brightness_range=[0.8, 1.2],\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True\n",
        "    )\n",
        "    augmented_images = []\n",
        "    for eye_image in eye_images:\n",
        "        eye_image = eye_image.reshape((1, ) + eye_image.shape)  # Reshape for Keras\n",
        "        for batch in datagen.flow(eye_image, batch_size=1):\n",
        "            augmented_images.append(batch[0])\n",
        "            if len(augmented_images) >= 5:  # Limiting to 5 augmentations per image for example\n",
        "                break\n",
        "    return np.array(augmented_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9cdyveNf3Kd"
      },
      "outputs": [],
      "source": [
        "def draw_bounding_boxes(image, eyes):\n",
        "    for _, (x, y, w, h) in eyes:\n",
        "        cv2.rectangle(image, (x, y), (x+w, y+h), (255, 0, 0), 2)  # Draw bounding box around the eye\n",
        "    return image\n",
        "\n",
        "# Load Haar cascades\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wC3XtWfrgGs_"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "\n",
        "dataset_folder = '/content/drive/MyDrive/NeurIPS/Code/Dataset(LPW)/LPW/1'\n",
        "def process_videos(dataset_folder):\n",
        "    video_files = glob.glob(os.path.join(dataset_folder, '*.mp4'))\n",
        "    for video_file in video_files:\n",
        "        video_name = os.path.basename(video_file).split('.')[0]\n",
        "        frames_folder = os.path.join(dataset_folder, video_name, 'frames')\n",
        "        extract_frames(video_file, frames_folder)\n",
        "\n",
        "        frame_files = glob.glob(os.path.join(frames_folder, '*.jpg'))\n",
        "        for frame_file in frame_files:\n",
        "            eyes = detect_faces_and_eyes(frame_file, face_cascade, eye_cascade)\n",
        "            if eyes:\n",
        "                aligned_eyes = align_and_normalize_eyes(eyes)\n",
        "                augmented_eyes = augment_eyes(aligned_eyes)\n",
        "\n",
        "                img = cv2.imread(frame_file)\n",
        "                img_with_boxes = draw_bounding_boxes(img, eyes)\n",
        "\n",
        "                for idx, eye_image in enumerate(augmented_eyes):\n",
        "                    eye_image_path = os.path.join(dataset_folder, video_name, 'eyes', f'eye_{idx}.jpg')\n",
        "                    if not os.path.exists(os.path.dirname(eye_image_path)):\n",
        "                        os.makedirs(os.path.dirname(eye_image_path))\n",
        "                    cv2.imwrite(eye_image_path, eye_image)\n",
        "\n",
        "                # Save the frame with bounding boxes\n",
        "                frame_with_boxes_path = os.path.join(dataset_folder, video_name, 'frames_with_boxes', os.path.basename(frame_file))\n",
        "                if not os.path.exists(os.path.dirname(frame_with_boxes_path)):\n",
        "                    os.makedirs(os.path.dirname(frame_with_boxes_path))\n",
        "                cv2.imwrite(frame_with_boxes_path, img_with_boxes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6KIZNaaQgJjH"
      },
      "outputs": [],
      "source": [
        "process_videos(videos_folder)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "source_root = '/content/videos/'\n",
        "destination_directory = '/content/sober_eye_images'\n",
        "os.makedirs(destination_directory, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "Q28sl21MCRmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_count = 0\n",
        "\n",
        "for root, dirs, files in os.walk(source_root):\n",
        "    for dir_name in dirs:\n",
        "        if dir_name == 'eyes':\n",
        "            eyes_folder_path = os.path.join(root, dir_name)\n",
        "            for image_name in os.listdir(eyes_folder_path):\n",
        "                image_path = os.path.join(eyes_folder_path, image_name)\n",
        "                if os.path.isfile(image_path):\n",
        "                    new_image_name = f'Sober{image_count}.jpg'\n",
        "                    new_image_path = os.path.join(destination_directory, new_image_name)\n",
        "                    shutil.copy(image_path, new_image_path)\n",
        "                    image_count += 1\n",
        "\n",
        "print(f\"Total images copied: {image_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOf9SfoNCtrT",
        "outputId": "af68b5c5-47d0-4dc5-faf3-b439cd45e22b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images copied: 549\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}